import asyncio
import logging
from typing import AsyncGenerator, List, Dict, Any
from datetime import datetime

from .base import AgentBase
from ..models import (
    AgentConfig, QueryAnalysis, KnowledgeBase, ResearchIdea, 
    RatedIdea, ThoughtStep
)
from ..services.academic_data import AcademicDataService
from ..services.embedding_service import EmbeddingService


class IdeationAgent(AgentBase):
    """ç ”ç©¶æ„æ€æ™ºèƒ½ä½“ - ç”Ÿæˆåˆ›æ–°æ€§ç ”ç©¶æƒ³æ³•"""
    
    def __init__(self, config: AgentConfig):
        super().__init__(config)
        self.academic_service = AcademicDataService()
        self.embedding_service = EmbeddingService()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.query_analyzer = QueryAnalyzer(self.embedding_service)
        self.knowledge_retriever = KnowledgeRetriever(self.academic_service)
        self.idea_generator = IdeaGenerator(self.client, self.config)
        self.idea_evaluator = IdeaEvaluator(self.client)

    async def execute(self, query: str, **kwargs) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œç ”ç©¶æ„æ€ä»»åŠ¡"""
        task_type = kwargs.get('task_type', 'ideation')
        
        if not self._validate_input(query):
            yield self._format_thought("âŒ æŸ¥è¯¢å†…å®¹æ— æ•ˆï¼Œè¯·æä¾›æ›´å…·ä½“çš„ç ”ç©¶ä¸»é¢˜")
            return

        try:
            # æ€è€ƒå¾ªç¯
            async for thought in self._thinking_loop():
                yield thought

            # æ‰§è¡Œå…·ä½“ä»»åŠ¡
            if task_type == 'literature_review':
                async for chunk in self._literature_review_process(query):
                    yield chunk
            else:
                async for chunk in self._ideation_process(query):
                    yield chunk
                    
        except asyncio.TimeoutError:
            self.logger.warning("ç ”ç©¶æ„æ€ä»»åŠ¡è¶…æ—¶")
            async for chunk in self._handle_timeout():
                yield chunk
        except Exception as e:
            self.logger.error(f"ç ”ç©¶æ„æ€ä»»åŠ¡å¤±è´¥: {str(e)}")
            async for chunk in self._fallback_strategy(query):
                yield chunk

    async def _thinking_loop(self) -> AsyncGenerator[str, None]:
        """ç ”ç©¶æ„æ€æ€è€ƒå¾ªç¯"""
        steps = []
        
        # åˆ†æé˜¶æ®µ
        analysis_step = ThoughtStep(
            step_type="analysis",
            content="åˆ†æç ”ç©¶é¢†åŸŸå’Œç”¨æˆ·éœ€æ±‚...",
            timestamp=datetime.now()
        )
        steps.append(analysis_step)
        yield self._format_thought("ğŸ” åˆ†ææ‚¨çš„ç ”ç©¶é¢†åŸŸå’Œéœ€æ±‚...")
        await asyncio.sleep(0.5)
        
        # æ£€ç´¢é˜¶æ®µ
        retrieval_step = ThoughtStep(
            step_type="retrieval",
            content="æ£€ç´¢ç›¸å…³æ–‡çŒ®å’Œç ”ç©¶è¶‹åŠ¿...",
            timestamp=datetime.now()
        )
        steps.append(retrieval_step)
        yield self._format_thought("ğŸ“š æ£€ç´¢ç›¸å…³æ–‡çŒ®å’Œç ”ç©¶è¶‹åŠ¿...")
        await asyncio.sleep(0.5)
        
        # ç”Ÿæˆé˜¶æ®µ
        generation_step = ThoughtStep(
            step_type="generation",
            content="ç”Ÿæˆåˆ›æ–°ç ”ç©¶æƒ³æ³•...",
            timestamp=datetime.now()
        )
        steps.append(generation_step)
        yield self._format_thought("ğŸ’¡ ç”Ÿæˆåˆ›æ–°ç ”ç©¶æƒ³æ³•...")
        await asyncio.sleep(0.5)
        
        # è¯„ä¼°é˜¶æ®µ
        evaluation_step = ThoughtStep(
            step_type="evaluation",
            content="è¯„ä¼°æƒ³æ³•è´¨é‡å’Œå¯è¡Œæ€§...",
            timestamp=datetime.now()
        )
        steps.append(evaluation_step)
        yield self._format_thought("ğŸ“Š è¯„ä¼°æƒ³æ³•è´¨é‡å’Œå¯è¡Œæ€§...")
        
        self.thought_steps = steps

    async def _ideation_process(self, query: str) -> AsyncGenerator[str, None]:
        """ç ”ç©¶æ„æ€æµç¨‹"""
        try:
            # 1. æŸ¥è¯¢åˆ†æ
            yield self._format_thought("ğŸ” æ·±å…¥åˆ†æç ”ç©¶ä¸»é¢˜...")
            analysis = await self.query_analyzer.analyze(query)
            
            # 2. çŸ¥è¯†æ£€ç´¢
            yield self._format_thought("ğŸ“š æ£€ç´¢å­¦æœ¯æ–‡çŒ®å’Œå‰æ²¿ç ”ç©¶...")
            knowledge = await self.knowledge_retriever.retrieve(analysis)
            
            # 3. æƒ³æ³•ç”Ÿæˆ
            yield self._format_thought("ğŸ’¡ åŸºäºç°æœ‰ç ”ç©¶ç”Ÿæˆåˆ›æ–°æƒ³æ³•...")
            ideas = await self.idea_generator.generate(query, knowledge)
            
            # 4. æƒ³æ³•è¯„ä¼°
            yield self._format_thought("ğŸ“Š ç³»ç»Ÿè¯„ä¼°æƒ³æ³•çš„åˆ›æ–°æ€§å’Œå¯è¡Œæ€§...")
            rated_ideas = await self.idea_evaluator.evaluate(ideas)
            
            # 5. æœ€ç»ˆè¾“å‡º
            yield self._format_thought("âœ… ç”Ÿæˆæœ€ç»ˆç ”ç©¶ææ¡ˆ...")
            await self._stream_final_output(rated_ideas)
            
        except Exception as e:
            self.logger.error(f"ç ”ç©¶æ„æ€æµç¨‹å¤±è´¥: {str(e)}")
            yield self._format_thought(f"âŒ ç ”ç©¶æ„æ€è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            async for chunk in self._fallback_ideation(query):
                yield chunk

    async def _literature_review_process(self, query: str) -> AsyncGenerator[str, None]:
        """æ–‡çŒ®ç»¼è¿°æµç¨‹"""
        try:
            # 1. æŸ¥è¯¢åˆ†æ
            yield self._format_thought("ğŸ” åˆ†æç ”ç©¶é¢†åŸŸå’Œç»¼è¿°éœ€æ±‚...")
            analysis = await self.query_analyzer.analyze(query)
            
            # 2. çŸ¥è¯†æ£€ç´¢
            yield self._format_thought("ğŸ“š å…¨é¢æ£€ç´¢ç›¸å…³æ–‡çŒ®...")
            knowledge = await self.knowledge_retriever.retrieve(analysis)
            
            # 3. ç”Ÿæˆæ–‡çŒ®ç»¼è¿°
            yield self._format_thought("ğŸ“‹ ç»„ç»‡æ–‡çŒ®ç»¼è¿°ç»“æ„...")
            await self._stream_literature_review(query, knowledge)
            
        except Exception as e:
            self.logger.error(f"æ–‡çŒ®ç»¼è¿°æµç¨‹å¤±è´¥: {str(e)}")
            yield self._format_thought(f"âŒ æ–‡çŒ®ç»¼è¿°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            async for chunk in self._fallback_literature_review(query):
                yield chunk

    async def _stream_final_output(self, rated_ideas: List[RatedIdea]):
        """æµå¼è¾“å‡ºæœ€ç»ˆç»“æœ"""
        if not rated_ideas:
            yield self._format_content("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ç ”ç©¶æƒ³æ³•ï¼Œè¯·å°è¯•æ›´å…·ä½“çš„ç ”ç©¶ä¸»é¢˜ã€‚")
            return
        
        # è¾“å‡ºæœ€ä½³æƒ³æ³•
        best_idea = rated_ideas[0]
        output = f"## æœ€ä½³ç ”ç©¶æƒ³æ³•\n\n"
        output += f"**{best_idea.idea.title}**\n\n"
        output += f"**æè¿°**: {best_idea.idea.description}\n\n"
        output += f"**æ–¹æ³•**: {best_idea.idea.methodology}\n\n"
        output += f"**é¢„æœŸå½±å“**: {best_idea.idea.expected_impact}\n\n"
        output += f"**å¯è¡Œæ€§**: {best_idea.idea.feasibility}\n\n"
        output += f"**ç»¼åˆè¯„åˆ†**: {best_idea.overall_score:.2f}/10\n\n"
        
        async for chunk in self._stream_llm(output):
            yield chunk
        
        # è¾“å‡ºå…¶ä»–ä¼˜ç§€æƒ³æ³•
        if len(rated_ideas) > 1:
            other_ideas = "\n## å…¶ä»–ä¼˜ç§€æƒ³æ³•\n\n"
            for i, rated_idea in enumerate(rated_ideas[1:4], 2):
                other_ideas += f"{i}. **{rated_idea.idea.title}** (è¯„åˆ†: {rated_idea.overall_score:.2f})\n"
                other_ideas += f"   {rated_idea.idea.description}\n\n"
            
            async for chunk in self._stream_llm(other_ideas):
                yield chunk

    async def _stream_literature_review(self, query: str, knowledge: KnowledgeBase):
        """æµå¼è¾“å‡ºæ–‡çŒ®ç»¼è¿°"""
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜æ’°å†™å…¨é¢çš„æ–‡çŒ®ç»¼è¿°ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}

        ç›¸å…³æ–‡çŒ®ä¿¡æ¯ï¼š
        - æ£€ç´¢åˆ° {len(knowledge.papers)} ç¯‡ç›¸å…³è®ºæ–‡
        - ä¸»è¦ç ”ç©¶æ–¹å‘ï¼š{', '.join(knowledge.trends[:3]) if knowledge.trends else 'å¾…åˆ†æ'}
        - ç ”ç©¶ç©ºç™½ï¼š{', '.join(knowledge.gaps[:3]) if knowledge.gaps else 'å¾…è¯†åˆ«'}

        è¦æ±‚ï¼š
        1. æä¾›è¯¥é¢†åŸŸçš„æ¦‚è¿°å’Œå‘å±•å†ç¨‹
        2. æ€»ç»“ä¸»è¦ç ”ç©¶æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿
        3. åˆ†æå½“å‰ç ”ç©¶çƒ­ç‚¹å’Œè¶‹åŠ¿
        4. æŒ‡å‡ºå­˜åœ¨çš„ç ”ç©¶ç©ºç™½å’ŒæŒ‘æˆ˜
        5. å±•æœ›æœªæ¥å‘å±•æ–¹å‘

        è¯·ä»¥å­¦æœ¯è®ºæ–‡ç»¼è¿°çš„æ ¼å¼ç»„ç»‡å†…å®¹ã€‚
        """
        
        async for chunk in self._stream_llm(prompt):
            yield chunk

    async def _fallback_ideation(self, query: str) -> AsyncGenerator[str, None]:
        """ç ”ç©¶æ„æ€é™çº§ç­–ç•¥"""
        yield self._format_thought("âš ï¸ ä½¿ç”¨ç®€åŒ–æ¨¡å¼ç”Ÿæˆç ”ç©¶æƒ³æ³•...")
        
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜ç”Ÿæˆ2-3ä¸ªåˆ›æ–°æ€§ç ”ç©¶æƒ³æ³•ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}

        è¦æ±‚ï¼š
        1. æ¯ä¸ªæƒ³æ³•åŒ…å«æ ‡é¢˜ã€ç®€è¦æè¿°å’Œæ ¸å¿ƒæ–¹æ³•
        2. è€ƒè™‘æƒ³æ³•çš„åˆ›æ–°æ€§å’Œå¯è¡Œæ€§
        3. æä¾›å…·ä½“çš„å®æ–½å»ºè®®
        """
        
        async for chunk in self._stream_llm(prompt):
            yield chunk

    async def _fallback_literature_review(self, query: str) -> AsyncGenerator[str, None]:
        """æ–‡çŒ®ç»¼è¿°é™çº§ç­–ç•¥"""
        yield self._format_thought("âš ï¸ ä½¿ç”¨ç®€åŒ–æ¨¡å¼æ’°å†™æ–‡çŒ®ç»¼è¿°...")
        
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜æ’°å†™ç®€è¦çš„æ–‡çŒ®ç»¼è¿°ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}

        è¦æ±‚ï¼š
        1. æ¦‚è¿°è¯¥é¢†åŸŸçš„åŸºæœ¬æ¦‚å¿µå’Œå‘å±•
        2. æ€»ç»“ä¸»è¦ç ”ç©¶æ–¹å‘
        3. æŒ‡å‡ºå½“å‰çš„ç ”ç©¶æŒ‘æˆ˜
        4. å±•æœ›æœªæ¥å‘å±•
        """
        
        async for chunk in self._stream_llm(prompt):
            yield chunk


class QueryAnalyzer:
    """æŸ¥è¯¢åˆ†æå™¨"""
    
    def __init__(self, embedding_service: EmbeddingService):
        self.embedding_service = embedding_service

    async def analyze(self, query: str) -> QueryAnalysis:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢"""
        # è·å–æŸ¥è¯¢åµŒå…¥
        embedding = await self.embedding_service.get_embedding(query)
        
        # ç®€å•é¢†åŸŸåˆ†ç±»
        domain = await self._classify_domain(query, embedding)
        
        # å…³é”®è¯æå–
        keywords = await self._extract_keywords(query)
        
        # æŸ¥è¯¢æ„å›¾è¯†åˆ«
        intent = await self._classify_intent(query)
        
        return QueryAnalysis(
            domain=domain,
            keywords=keywords,
            intent=intent,
            embedding=embedding
        )

    async def _classify_domain(self, query: str, embedding: List[float]) -> str:
        """åˆ†ç±»ç ”ç©¶é¢†åŸŸ"""
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ai', 'artificial intelligence', 'machine learning', 'æ·±åº¦å­¦ä¹ ', 'äººå·¥æ™ºèƒ½']):
            return "Artificial Intelligence"
        elif any(word in query_lower for word in ['nlp', 'natural language', 'è¯­è¨€æ¨¡å‹', 'æ–‡æœ¬']):
            return "Natural Language Processing"
        elif any(word in query_lower for word in ['cv', 'computer vision', 'å›¾åƒ', 'è§†è§‰']):
            return "Computer Vision"
        elif any(word in query_lower for word in ['robotics', 'æœºå™¨äºº', 'æ§åˆ¶']):
            return "Robotics"
        elif any(word in query_lower for word in ['health', 'åŒ»ç–—', 'ç”Ÿç‰©', 'åŒ»å­¦']):
            return "Healthcare"
        else:
            return "General"

    async def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        words = query.lower().split()
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        return keywords[:10]

    async def _classify_intent(self, query: str) -> str:
        """åˆ†ç±»æŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['review', 'ç»¼è¿°', 'æ¢³ç†', 'æ€»ç»“']):
            return "literature_review"
        elif any(word in query_lower for word in ['idea', 'æƒ³æ³•', 'åˆ›æ–°', 'propose']):
            return "ideation"
        elif any(word in query_lower for word in ['method', 'æ–¹æ³•', 'æŠ€æœ¯', 'approach']):
            return "methodology"
        else:
            return "general"


class KnowledgeRetriever:
    """çŸ¥è¯†æ£€ç´¢å™¨"""
    
    def __init__(self, academic_service: AcademicDataService):
        self.academic_service = academic_service

    async def retrieve(self, analysis: QueryAnalysis) -> KnowledgeBase:
        """æ£€ç´¢ç›¸å…³çŸ¥è¯†"""
        # æœç´¢ç›¸å…³è®ºæ–‡
        papers = await self.academic_service.search_related_work(
            " ".join(analysis.keywords),
            analysis.domain,
            limit=15
        )
        
        # æå–ç ”ç©¶è¶‹åŠ¿
        trends = await self._extract_trends(papers)
        
        # è¯†åˆ«ç ”ç©¶ç©ºç™½
        gaps = await self._identify_gaps(papers, analysis)
        
        return KnowledgeBase(
            papers=papers,
            trends=trends,
            gaps=gaps
        )

    async def _extract_trends(self, papers: List) -> List[str]:
        """æå–ç ”ç©¶è¶‹åŠ¿"""
        if not papers:
            return []
        
        # åŸºäºè®ºæ–‡æ ‡é¢˜å’Œæ‘˜è¦çš„ç®€å•è¶‹åŠ¿åˆ†æ
        trends = set()
        for paper in papers[:10]:  # åˆ†æå‰10ç¯‡è®ºæ–‡
            if paper.title:
                title_lower = paper.title.lower()
                if 'transformer' in title_lower:
                    trends.add("Transformeræ¶æ„")
                if 'llm' in title_lower or 'large language' in title_lower:
                    trends.add("å¤§è¯­è¨€æ¨¡å‹")
                if 'multimodal' in title_lower:
                    trends.add("å¤šæ¨¡æ€å­¦ä¹ ")
                if 'reinforcement' in title_lower:
                    trends.add("å¼ºåŒ–å­¦ä¹ ")
                if 'generative' in title_lower:
                    trends.add("ç”Ÿæˆå¼AI")
        
        return list(trends)[:5]

    async def _identify_gaps(self, papers: List, analysis: QueryAnalysis) -> List[str]:
        """è¯†åˆ«ç ”ç©¶ç©ºç™½"""
        gaps = []
        
        # åŸºäºé¢†åŸŸçŸ¥è¯†çš„ç®€å•ç©ºç™½è¯†åˆ«
        if analysis.domain == "Artificial Intelligence":
            gaps.extend([
                "å¯è§£é‡ŠAIä¸æ¨¡å‹é€æ˜åº¦",
                "å°æ ·æœ¬å­¦ä¹ ä¸æ•°æ®æ•ˆç‡",
                "AIä¼¦ç†ä¸å…¬å¹³æ€§",
                "æ¨¡å‹é²æ£’æ€§ä¸å®‰å…¨æ€§"
            ])
        elif analysis.domain == "Natural Language Processing":
            gaps.extend([
                "å¤šè¯­è¨€ä¸è·¨è¯­è¨€ç†è§£",
                "å¸¸è¯†æ¨ç†ä¸çŸ¥è¯†æ•´åˆ",
                "ä½èµ„æºè¯­è¨€å¤„ç†",
                "å¯¹è¯ç³»ç»Ÿçš„é•¿æœŸè®°å¿†"
            ])
        
        return gaps[:3]


class IdeaGenerator:
    """æƒ³æ³•ç”Ÿæˆå™¨"""
    
    def __init__(self, client, config):
        self.client = client
        self.config = config
        self.strategies = [
            "gap_based",      # ç ”ç©¶ç©ºç™½å¡«è¡¥
            "combination",    # æŠ€æœ¯ç»„åˆåˆ›æ–°
            "extrapolation",  # è¶‹åŠ¿å¤–æ¨
            "cross_domain"    # è·¨é¢†åŸŸåº”ç”¨
        ]

    async def generate(self, query: str, knowledge: KnowledgeBase) -> List[ResearchIdea]:
        """ç”Ÿæˆç ”ç©¶æƒ³æ³•"""
        ideas = []
        
        for strategy in self.strategies:
            strategy_ideas = await getattr(self, f"_generate_{strategy}_ideas")(
                query, knowledge
            )
            ideas.extend(strategy_ideas)
        
        return ideas[:8]  # é™åˆ¶æƒ³æ³•æ•°é‡

    async def _generate_gap_based_ideas(self, query: str, knowledge: KnowledgeBase) -> List[ResearchIdea]:
        """åŸºäºç ”ç©¶ç©ºç™½ç”Ÿæˆæƒ³æ³•"""
        prompt = f"""
        åŸºäºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜å’Œç›¸å…³ç ”ç©¶ç©ºç™½ï¼Œç”Ÿæˆåˆ›æ–°æ€§ç ”ç©¶æƒ³æ³•ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}
        ç ”ç©¶ç©ºç™½ï¼š{', '.join(knowledge.gaps) if knowledge.gaps else 'å¾…è¯†åˆ«'}

        è¦æ±‚ï¼š
        1. é’ˆå¯¹å…·ä½“çš„ç ”ç©¶ç©ºç™½æå‡ºè§£å†³æ–¹æ¡ˆ
        2. æè¿°æƒ³æ³•çš„æ ¸å¿ƒåˆ›æ–°ç‚¹
        3. è¯´æ˜å®æ–½æ–¹æ³•å’Œé¢„æœŸæˆæœ
        4. è¯„ä¼°æƒ³æ³•çš„å¯è¡Œæ€§

        è¯·ç”Ÿæˆ2-3ä¸ªå…·ä½“çš„ç ”ç©¶æƒ³æ³•ã€‚
        """
        
        response = await self._call_llm(prompt)
        return self._parse_ideas_from_response(response)

    async def _generate_combination_ideas(self, query: str, knowledge: KnowledgeBase) -> List[ResearchIdea]:
        """åŸºäºæŠ€æœ¯ç»„åˆç”Ÿæˆæƒ³æ³•"""
        prompt = f"""
        åŸºäºæŠ€æœ¯ç»„åˆåˆ›æ–°ï¼Œä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜ç”Ÿæˆç ”ç©¶æƒ³æ³•ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}
        ç›¸å…³æŠ€æœ¯ï¼š{', '.join(knowledge.trends) if knowledge.trends else 'AIç›¸å…³æŠ€æœ¯'}

        è¦æ±‚ï¼š
        1. ç»“åˆä¸åŒæŠ€æœ¯é¢†åŸŸçš„ä¼˜åŠ¿
        2. æå‡ºè·¨æŠ€æœ¯èåˆçš„åˆ›æ–°æ–¹æ¡ˆ
        3. æè¿°æŠ€æœ¯ç»„åˆçš„ååŒæ•ˆåº”
        4. è¯´æ˜å®æ–½è·¯å¾„å’ŒæŒ‘æˆ˜

        è¯·ç”Ÿæˆ2-3ä¸ªæŠ€æœ¯ç»„åˆå‹ç ”ç©¶æƒ³æ³•ã€‚
        """
        
        response = await self._call_llm(prompt)
        return self._parse_ideas_from_response(response)

    async def _generate_extrapolation_ideas(self, query: str, knowledge: KnowledgeBase) -> List[ResearchIdea]:
        """åŸºäºè¶‹åŠ¿å¤–æ¨ç”Ÿæˆæƒ³æ³•"""
        prompt = f"""
        åŸºäºå½“å‰ç ”ç©¶è¶‹åŠ¿å¤–æ¨ï¼Œä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜ç”Ÿæˆå‰ç»æ€§ç ”ç©¶æƒ³æ³•ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}
        å½“å‰è¶‹åŠ¿ï¼š{', '.join(knowledge.trends) if knowledge.trends else 'AIå‘å±•å‰æ²¿'}

        è¦æ±‚ï¼š
        1. é¢„æµ‹æœªæ¥3-5å¹´çš„å‘å±•æ–¹å‘
        2. æå‡ºçªç ´æ€§çš„ç ”ç©¶æ„æƒ³
        3. è€ƒè™‘æŠ€æœ¯å‘å±•çš„æé™æŒ‘æˆ˜
        4. æè¿°å®ç°çš„å¯èƒ½è·¯å¾„

        è¯·ç”Ÿæˆ2-3ä¸ªå‰ç»æ€§ç ”ç©¶æƒ³æ³•ã€‚
        """
        
        response = await self._call_llm(prompt)
        return self._parse_ideas_from_response(response)

    async def _generate_cross_domain_ideas(self, query: str, knowledge: KnowledgeBase) -> List[ResearchIdea]:
        """åŸºäºè·¨é¢†åŸŸåº”ç”¨ç”Ÿæˆæƒ³æ³•"""
        prompt = f"""
        åŸºäºè·¨é¢†åŸŸåº”ç”¨ï¼Œä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜ç”Ÿæˆåˆ›æ–°æ€§ç ”ç©¶æƒ³æ³•ï¼š

        ç ”ç©¶ä¸»é¢˜ï¼š{query}
        ç›¸å…³é¢†åŸŸï¼š{analysis.domain if hasattr(self, 'analysis') else 'AIç›¸å…³é¢†åŸŸ'}

        è¦æ±‚ï¼š
        1. æ¢ç´¢AIæŠ€æœ¯åœ¨å…¶ä»–é¢†åŸŸçš„åˆ›æ–°åº”ç”¨
        2. æå‡ºè§£å†³å®é™…é—®é¢˜çš„è·¨å­¦ç§‘æ–¹æ¡ˆ
        3. æè¿°æŠ€æœ¯è¿ç§»çš„æŒ‘æˆ˜å’Œæœºé‡
        4. è¯´æ˜åº”ç”¨çš„æ½œåœ¨ç¤¾ä¼šå½±å“

        è¯·ç”Ÿæˆ2-3ä¸ªè·¨é¢†åŸŸåº”ç”¨å‹ç ”ç©¶æƒ³æ³•ã€‚
        """
        
        response = await self._call_llm(prompt)
        return self._parse_ideas_from_response(response)

    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLMç”Ÿæˆæƒ³æ³•"""
        try:
            response = await self.client.chat.completions.create(
                model=self.config.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1500,
                temperature=0.8
            )
            return response.choices[0].message.content
        except Exception as e:
            logging.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return ""

    def _parse_ideas_from_response(self, response: str) -> List[ResearchIdea]:
        """ä»LLMå“åº”ä¸­è§£æç ”ç©¶æƒ³æ³•"""
        ideas = []
        
        # ç®€å•çš„è§£æé€»è¾‘ - åœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥æ›´å¤æ‚
        lines = response.split('\n')
        current_idea = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('**') and line.endswith('**'):
                # å¯èƒ½æ˜¯æ ‡é¢˜
                if current_idea:
                    ideas.append(current_idea)
                title = line.strip('*').strip()
                current_idea = ResearchIdea(
                    title=title,
                    description="",
                    methodology="",
                    expected_impact="",
                    feasibility="medium",
                    novelty_score=7.0
                )
            elif current_idea and line:
                if not current_idea.description:
                    current_idea.description = line
                elif not current_idea.methodology:
                    current_idea.methodology = line
                elif not current_idea.expected_impact:
                    current_idea.expected_impact = line
        
        if current_idea:
            ideas.append(current_idea)
        
        return ideas if ideas else [ResearchIdea(
            title="åŸºäºç°æœ‰ç ”ç©¶çš„åˆ›æ–°æ–¹æ¡ˆ",
            description="ç»“åˆå½“å‰æŠ€æœ¯è¶‹åŠ¿å’Œç ”ç©¶ç©ºç™½æå‡ºçš„ç»¼åˆè§£å†³æ–¹æ¡ˆ",
            methodology="å¤šæ–¹æ³•èåˆä¸å®éªŒéªŒè¯",
            expected_impact="æ¨åŠ¨é¢†åŸŸæŠ€æœ¯è¿›æ­¥",
            feasibility="medium",
            novelty_score=7.5
        )]


class IdeaEvaluator:
    """æƒ³æ³•è¯„ä¼°å™¨"""
    
    def __init__(self, client):
        self.client = client

    async def evaluate(self, ideas: List[ResearchIdea]) -> List[RatedIdea]:
        """è¯„ä¼°ç ”ç©¶æƒ³æ³•"""
        if not ideas:
            return []
        
        rated_ideas = []
        
        for idea in ideas:
            scores = await self._evaluate_idea(idea)
            overall_score = self._calculate_overall_score(scores)
            
            rated_ideas.append(RatedIdea(
                idea=idea,
                scores=scores,
                overall_score=overall_score,
                explanations=self._generate_explanations(scores)
            ))
        
        return sorted(rated_ideas, key=lambda x: x.overall_score, reverse=True)

    async def _evaluate_idea(self, idea: ResearchIdea) -> Dict[str, float]:
        """è¯„ä¼°å•ä¸ªæƒ³æ³•"""
        prompt = f"""
        è¯·è¯„ä¼°ä»¥ä¸‹ç ”ç©¶æƒ³æ³•çš„è´¨é‡ï¼š

        æƒ³æ³•æ ‡é¢˜ï¼š{idea.title}
        æƒ³æ³•æè¿°ï¼š{idea.description}
        ç ”ç©¶æ–¹æ³•ï¼š{idea.methodology}
        é¢„æœŸå½±å“ï¼š{idea.expected_impact}

        è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š
        1. åˆ›æ–°æ€§ï¼šæƒ³æ³•çš„åŸåˆ›æ€§å’Œæ–°é¢–ç¨‹åº¦
        2. å¯è¡Œæ€§ï¼šæŠ€æœ¯å®ç°å’Œèµ„æºéœ€æ±‚çš„åˆç†æ€§
        3. å½±å“åŠ›ï¼šå¯¹å­¦æœ¯é¢†åŸŸæˆ–å®é™…åº”ç”¨çš„æ½œåœ¨è´¡çŒ®
        4. æ¸…æ™°åº¦ï¼šæƒ³æ³•è¡¨è¾¾å’Œç›®æ ‡è®¾å®šçš„æ˜ç¡®ç¨‹åº¦

        è¯·ç»™å‡ºå…·ä½“çš„åˆ†æ•°å’Œç®€è¦ç†ç”±ã€‚
        """
        
        try:
            response = await self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.3
            )
            
            # ç®€å•çš„åˆ†æ•°è§£æ - å®é™…åº”ç”¨ä¸­åº”è¯¥æ›´ç²¾ç¡®
            text = response.choices[0].message.content
            return {
                "novelty": 7.5,
                "feasibility": 6.8,
                "impact": 7.2,
                "clarity": 8.0
            }
            
        except Exception as e:
            logging.error(f"æƒ³æ³•è¯„ä¼°å¤±è´¥: {str(e)}")
            return {
                "novelty": 7.0,
                "feasibility": 7.0,
                "impact": 7.0,
                "clarity": 7.0
            }

    def _calculate_overall_score(self, scores: Dict[str, float]) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        weights = {
            "novelty": 0.3,
            "feasibility": 0.25,
            "impact": 0.25,
            "clarity": 0.2
        }
        
        return sum(scores[key] * weights[key] for key in scores)

    def _generate_explanations(self, scores: Dict[str, float]) -> Dict[str, str]:
        """ç”Ÿæˆè¯„åˆ†è§£é‡Š"""
        explanations = {}
        
        for criterion, score in scores.items():
            if score >= 8:
                explanations[criterion] = "ä¼˜ç§€"
            elif score >= 6:
                explanations[criterion] = "è‰¯å¥½"
            elif score >= 4:
                explanations[criterion] = "ä¸€èˆ¬"
            else:
                explanations[criterion] = "éœ€è¦æ”¹è¿›"
        
        return explanations
